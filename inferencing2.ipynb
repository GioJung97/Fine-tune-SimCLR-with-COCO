{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76810b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe18cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_coco(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f5fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_cat_mapping(train_coco):\n",
    "    cat_ids = sorted({c[\"id\"] for c in train_coco[\"categories\"]})\n",
    "    catid_to_idx = {cid: i for i, cid in enumerate(cat_ids)}\n",
    "    return catid_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74fcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoObjectCropClassification(Dataset):\n",
    "    def __init__(self, images_dir, coco_json_path, catid_to_idx, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.catid_to_idx = catid_to_idx\n",
    "\n",
    "        coco = _load_coco(coco_json_path)\n",
    "\n",
    "        self.img_by_id = {img[\"id\"]: img for img in coco[\"images\"]}\n",
    "\n",
    "        # Build samples from annotations\n",
    "        self.samples = []\n",
    "        bad_category = 0\n",
    "\n",
    "        for ann in coco[\"annotations\"]:\n",
    "            cid = ann[\"category_id\"]\n",
    "            if cid not in self.catid_to_idx:\n",
    "                bad_category += 1\n",
    "                continue\n",
    "\n",
    "            img_info = self.img_by_id.get(ann[\"image_id\"])\n",
    "            if img_info is None:\n",
    "                continue\n",
    "\n",
    "            self.samples.append({\n",
    "                \"file_name\": img_info[\"file_name\"],\n",
    "                \"bbox\": ann[\"bbox\"],  # [x,y,w,h]\n",
    "                \"label\": self.catid_to_idx[cid],\n",
    "            })\n",
    "\n",
    "        if bad_category > 0:\n",
    "            print(f\"[WARN] Skipped {bad_category} annotations with category_id not in train mapping.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        img_path = os.path.join(self.images_dir, s[\"file_name\"])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        x, y, w, h = s[\"bbox\"]\n",
    "        left   = int(round(x))\n",
    "        top    = int(round(y))\n",
    "        right  = int(round(x + w))\n",
    "        bottom = int(round(y + h))\n",
    "\n",
    "        # Clamp to image bounds (prevents crashes on weird bboxes)\n",
    "        W, H = image.size\n",
    "        left = max(0, min(left, W - 1))\n",
    "        top = max(0, min(top, H - 1))\n",
    "        right = max(left + 1, min(right, W))\n",
    "        bottom = max(top + 1, min(bottom, H))\n",
    "\n",
    "        crop = image.crop((left, top, right, bottom))\n",
    "        label = s[\"label\"]\n",
    "\n",
    "        if self.transform:\n",
    "            crop = self.transform(crop)\n",
    "\n",
    "        return crop, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f10fbea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 424\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_root = \"./coco\"\n",
    "test_dir = os.path.join(data_root, \"test\")\n",
    "\n",
    "test_json = os.path.join(test_dir, \"_annotations.coco.json\")\n",
    "\n",
    "image_size = 224\n",
    "test_tf = T.Compose([\n",
    "    T.Resize((image_size, image_size)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "test_coco = _load_coco(test_json)\n",
    "test_catid_to_idx = _build_cat_mapping(test_coco)\n",
    "\n",
    "test_ds = CocoObjectCropClassification(test_dir, test_json, catid_to_idx=test_catid_to_idx, transform=test_tf)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"Test samples:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c2799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/917160535/miniconda3/envs/gioConda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/917160535/miniconda3/envs/gioConda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import get_resnet\n",
    "\n",
    "# ---- set these to what you trained with ----\n",
    "resnet_name = \"resnet50\"\n",
    "projection_dim = 64\n",
    "\n",
    "class SimCLRFinetuneClassifier(nn.Module):\n",
    "    def __init__(self, simclr_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.simclr = simclr_model\n",
    "        self.classifier = nn.Linear(self.simclr.n_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _, _, _ = self.simclr(x, x)\n",
    "        return self.classifier(h)\n",
    "\n",
    "ckpt_path = \"/data2/gio/bobyard/finetuned_model/simclr_finetuned_epoch_19.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "encoder = get_resnet(resnet_name, pretrained=False)\n",
    "n_features = encoder.fc.in_features\n",
    "simclr_model = SimCLR(encoder, projection_dim, n_features)\n",
    "\n",
    "model = SimCLRFinetuneClassifier(simclr_model, checkpoint[\"num_classes\"])\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "catid_to_idx = checkpoint[\"catid_to_idx\"]\n",
    "print(f\"Number of classes: {len(catid_to_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1edf6672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Top-1 Acc: 0.9835\n",
      "Test Top-5 Acc: 0.9929\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate(loader, model):\n",
    "    correct1 = 0\n",
    "    correct5 = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "\n",
    "            # top-1\n",
    "            pred1 = logits.argmax(dim=1)\n",
    "            correct1 += (pred1 == y).sum().item()\n",
    "\n",
    "            # top-5 (safe if num_classes < 5)\n",
    "            k = min(5, logits.size(1))\n",
    "            topk = logits.topk(k, dim=1).indices\n",
    "            correct5 += (topk == y.unsqueeze(1)).any(dim=1).sum().item()\n",
    "\n",
    "            total += y.size(0)\n",
    "\n",
    "            all_preds.append(pred1.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    acc1 = correct1 / total\n",
    "    acc5 = correct5 / total\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    return acc1, acc5, all_labels, all_preds\n",
    "\n",
    "acc1, acc5, y_true, y_pred = evaluate(test_loader, model)\n",
    "print(f\"Test Top-1 Acc: {acc1:.4f}\")\n",
    "print(f\"Test Top-5 Acc: {acc5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c70376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix shape: (31, 31)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     1.0000    1.0000    1.0000       149\n",
      "           2     1.0000    1.0000    1.0000        17\n",
      "           3     1.0000    1.0000    1.0000         3\n",
      "           4     1.0000    1.0000    1.0000        25\n",
      "           5     0.8621    1.0000    0.9259        25\n",
      "           6     1.0000    1.0000    1.0000         4\n",
      "           8     1.0000    1.0000    1.0000         5\n",
      "           9     1.0000    1.0000    1.0000         5\n",
      "          10     0.0000    0.0000    0.0000         1\n",
      "          11     0.0000    0.0000    0.0000         0\n",
      "          12     1.0000    1.0000    1.0000         3\n",
      "          15     1.0000    0.6667    0.8000         9\n",
      "          16     1.0000    1.0000    1.0000        59\n",
      "          17     1.0000    1.0000    1.0000        19\n",
      "          18     1.0000    1.0000    1.0000         5\n",
      "          20     1.0000    1.0000    1.0000         1\n",
      "          22     1.0000    1.0000    1.0000        22\n",
      "          23     1.0000    1.0000    1.0000         7\n",
      "          24     1.0000    1.0000    1.0000         3\n",
      "          25     1.0000    1.0000    1.0000        16\n",
      "          26     1.0000    0.7692    0.8696        13\n",
      "          28     1.0000    1.0000    1.0000         5\n",
      "          29     1.0000    1.0000    1.0000         9\n",
      "          30     1.0000    1.0000    1.0000         3\n",
      "          32     1.0000    1.0000    1.0000         1\n",
      "          33     1.0000    1.0000    1.0000         2\n",
      "          34     1.0000    1.0000    1.0000         2\n",
      "          35     1.0000    1.0000    1.0000         4\n",
      "          38     1.0000    1.0000    1.0000         1\n",
      "          40     1.0000    1.0000    1.0000         4\n",
      "          41     1.0000    1.0000    1.0000         2\n",
      "\n",
      "    accuracy                         0.9835       424\n",
      "   macro avg     0.9310    0.9173    0.9224       424\n",
      "weighted avg     0.9895    0.9835    0.9850       424\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/917160535/miniconda3/envs/gioConda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/917160535/miniconda3/envs/gioConda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/917160535/miniconda3/envs/gioConda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/917160535/miniconda3/envs/gioConda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/917160535/miniconda3/envs/gioConda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/917160535/miniconda3/envs/gioConda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix shape:\", cm.shape)\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gioConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
